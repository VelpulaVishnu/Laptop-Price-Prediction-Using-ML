# -*- coding: utf-8 -*-
"""Laptop_price_prediction_Vishnu_ipynb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IqeaPDFiE_rSa9eE6REWPZTXIzVS4pkK

#Problem Statement: Laptop Price Prediction for SmartTech Co.

SmartTech Co., a leading technology company, aims to strengthen its market competitiveness by understanding and accurately estimating laptop prices based on key hardware and brand features. With the rapid evolution of laptop technologies and an expanding product range across different brands, manual pricing strategies are becoming inefficient and prone to inaccuracies.

To address this challenge, SmartTech Co. seeks to develop a machine learning model that can predict laptop prices based on specifications such as brand, processor type, RAM, storage, screen size, GPU, operating system, and weight.

The goal is not only to achieve accurate price predictions but also to gain insights into how various factors influence pricing, enabling data-driven decisions for:

Competitive pricing strategy

Product positioning

Brand impact analysis

The project must ensure that the model is interpretable, scalable, and capable of real-time predictions for newly launched laptops, allowing SmartTech Co. to dynamically adapt to market trends.

#importing necessary libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""#loading the data set and performing data exploration"""

df=pd.read_csv('laptop.csv')
df.head()

#checking shape of dataset
df.shape

#checking info of dataset
df.info()

#unique values per column
df.nunique()

#getting statistical information on continuous variables
df.describe()

"""#Data preprocessing
##1.Feature Engineering <br>
###(i).Data Cleaning
"""

#firstly i want to know how many columns are there in dataset
df.columns

#as we see that ['         ', 'Unnamed: 0'] columns are not required so we need to drop them
df.drop(columns=['      ','Unnamed: 0'],inplace=True,axis=1)
df.head()

#checking null values
df.isnull().sum()

#removing null values
df.dropna(inplace=True)
df.isnull().sum()

#checking duplicates
df.duplicated().sum()

#getting the duplicated values
df[df.duplicated()]

#dropping duplicates
df.drop_duplicates(keep='first',inplace=True)
df.duplicated().sum()

#resetting index after dropping records
df.reset_index(drop=True,inplace=True)

df.info()

"""#company column"""

#checking unique values in company column
df['Company'].unique()

df['Company'].value_counts()

"""#Typename column"""

df["TypeName"].unique()

df['TypeName'].value_counts()

"""#Inches column"""

df["Inches"].unique()

# as we have seen that there is wrong data "?" and wrong data type as object but it is float so we need to change it
df['Inches'].value_counts()

#lets see for which company is it is
df[df['Inches']=='?']

#replacing "?" with 15.6 inches beacuse for that model the screen size is 15.6
df['Inches']=df['Inches'].replace('?',15.6)
df['Inches']=df['Inches'].astype('float')
df['Inches'].unique()

df.info()

#Now lets check for outliers in this inches column
# Set figure size
plt.figure(figsize=(12, 5))

# Histogram
plt.subplot(1, 2, 1)
sns.histplot(df['Inches'], kde=True, bins=15, color='orange')
plt.title('Distribution of Laptop Screen Size (Inches)')
plt.xlabel('Inches')
plt.ylabel('Count')

#  Boxplot
plt.subplot(1, 2, 2)
sns.boxplot(x=df['Inches'], color='red')
plt.title('Boxplot of Laptop Screen Size (Inches)')
plt.xlabel('Inches')

plt.tight_layout()
plt.show()

"""##there are outliers in our inches column so we need to tackle outliers because due to outliers our statistical analysis will go wrong and we get inaccurate predictions"""

df.describe()

#replace outliers using IQR method(Winsorization)
Q1= np.percentile(df['Inches'],25)
Q3= np.percentile(df['Inches'],75)

IQR=Q3-Q1

lower_limit=Q1-1.5*IQR
upper_limit=Q3+1.5*IQR


df['Inches'].clip(lower_limit,upper_limit,inplace=True)

#Now lets recheck for outliers in this inches column
# Set figure size
plt.figure(figsize=(12, 5))

# Histogram
plt.subplot(1, 2, 1)
sns.histplot(df['Inches'], kde=True, bins=15, color='orange')
plt.title('Distribution of Laptop Screen Size (Inches)')
plt.xlabel('Inches')
plt.ylabel('Count')

#  Boxplot
plt.subplot(1, 2, 2)
sns.boxplot(x=df['Inches'], color='red')
plt.title('Boxplot of Laptop Screen Size (Inches)')
plt.xlabel('Inches')

plt.tight_layout()
plt.show()

df['Inches'].skew()

df.head()

"""#ScreenResolution column"""

df1=df.copy()
df1[ 'ScreenResolution'].unique()

"""##We see that there are 40 unique values in this column we need to perform dimensionality reduction inorder reduce complexity,overfitting
 steps<br>
##1.We are trying to extract the numeric screen resolution values (width Ã— height) from strings that look like "1920x1080" or "2560x1600".After extracting, the values are still strings (text) â€” like '1920' and '1080'.so i did converted them to numeric because the machine doesnt understand the text data
###=============================================================================
##2.we need to create a touchscreen and IPS columns because Touchscreens usually make laptops more expensive, so this feature will likely have a positive correlation with price.if touchscreen is there replace it with one else 0 and simillarly for IPS(in-plane switching)IPS display	   ðŸ’¸ Increases price due to better panel quality
###=============================================================================
##3.created ppi column(pixels per inch column)

"""

df1['ScreenResolution'].str.strip()

# Split by 'x' to get width and height
df1['X_res'] = df1['ScreenResolution'].apply(lambda x: x.split('x')[0][-4:])  # here we get last 4 digits before x
df1['Y_res'] = df1['ScreenResolution'].apply(lambda x: x.split('x')[1][:4])  # here we get first 4 digits after x

# Convert to integers safely
df1['X_res'] = df1['X_res'].astype(int)
df1['Y_res'] = df1['Y_res'].astype(int)
df1.head()

df1['Touchscreen'] = df1['ScreenResolution'].apply(lambda x: 1 if 'Touchscreen' in x else 0)
df1['IPS'] = df1['ScreenResolution'].apply(lambda x: 1 if 'IPS' in x else 0)
df1

#creating new column 'Dispaly' using above function
df1['ppi'] = (((df1['X_res']**2) + (df1['Y_res']**2))**0.5/df1['Inches']).astype('float')

#dropping  columns
df1.drop(columns=['ScreenResolution'],inplace=True)

df1.drop(columns=['Inches','X_res','Y_res'],inplace=True)

df1.info()

"""#CPU column
## Created CPU brand column by extracting all kind of cpu brand like intel ,AMD etc...
"""

#created a copy of df1 and stored in df2
df2=df1.copy()
print("Unique values in CPU column : \n",df2['Cpu'].unique())
print("Number of unique values :",len(df2['Cpu'].unique()))

#creating a function to extract cpu brand from cpu column
def extract_cpu_brand(cpu_name):
    cpu_name = cpu_name.lower()
    cpu_map = {
        'i3': 'Intel Core i3',
        'i5': 'Intel Core i5',
        'i7': 'Intel Core i7',
        'pentium': 'Intel Pentium',
        'celeron': 'Intel Celeron',
        'atom': 'Intel Atom',
        'e-series': 'AMD E-Series',
        'fx': 'AMD FX',
        'ryzen': 'AMD Ryzen',
        'a4': 'AMD A4-Series',
        'a6': 'AMD A6-Series',
        'a8': 'AMD A8-Series',
        'a9': 'AMD A9-Series',
        'a10': 'AMD A10-Series',
        'a12': 'AMD A12-Series',
        'cortex': 'Samsung Cortex'
    }

    for key, value in cpu_map.items():
        if key in cpu_name:
            return value
    return 'Other Intel Processor'

#applying function to cpu column and creating cpu brand column
df2['CPU_Brand'] = df['Cpu'].apply(extract_cpu_brand)
df2.head()

df2['CPU_Brand'].value_counts().plot(kind='bar')

sns.barplot(x=df2['CPU_Brand'],y=df2['Price'])
plt.xticks(rotation='vertical')
plt.show()

#dropping original cpu column
df2.drop(columns=['Cpu'],inplace=True)
df2.head()

"""#Ram Column"""

#checking unique values
df2['Ram'].unique()

#seperating GB from ram
df2['Ram']=df2['Ram'].str.replace('GB','')

#converting ram to integer type
df2['Ram']= df2['Ram'].astype('int')
df2.head()

"""#Memory column"""

#creating a copy of df2 and storing in df3 variable
df3=df2.copy()

# In memory column there are many unique values we need perform dimensionality reduction
df3["Memory"].unique()

df3['Memory'].value_counts()

#checking error value
df3[df3['Memory']=='?']

#replacing error value with  mode
df3['Memory']=df3['Memory'].str.replace('?.','516GB SSD')

#creating fun to extract and categorize SSD
def category(x):
  if '8GB SSD' in x:
    return 8
  elif '16GB SSD' in x:
    return 16
  elif '32GB SSD' in x:
    return 32
  elif '64GB SSD' in x:
    return 64
  elif '128GB SSD' in x:
    return 128
  elif '180GB SSD' in x:
    return 180
  elif '240GB SSD' in x:
    return 240
  elif '256GB SSD' in x:
    return 256
  elif '512GB SSD' in x:
    return 512
  elif '1TB SSD' in x:
    return 1000
  else:
    return 0

#creating new column SSD using above function
df3['SSD']=df3['Memory'].apply(category)

df3['SSD'].unique()

#creating function to extract and categorize HDD
def category(x):
  if '32GB HDD'in x:
    return 32
  elif '128GB HDD' in x:
    return 128
  elif '500GB HDD' in x:
    return 500
  elif '1TB HDD' in x:
    return 1000
  elif '1.0TB HDD' in x:
    return 1000
  elif '2TB HDD' in x:
    return 2000
  else:
    return 0

#creating new column HDD using above function
df3['HDD']=df3['Memory'].apply(category)

df3['HDD'].unique()

#similarly creating function to extract flash storage
def category(x):
  if '16GB Flash' in x:
    return 16
  elif '32GB Flash' in x:
    return 32
  elif '64GB Flash' in x:
    return 64
  elif '128GB Flash' in x:
    return 128
  elif '256GB Flash' in x:
    return 256
  elif '512GB Flash' in x:
    return 512
  else:
    return 0

#creating new column flash stoarage using above function
df3['Flash_Storage']=df3['Memory'].apply(category)

df3['Flash_Storage'].unique()

#creating new column hybrid storage
df3['Hybrid_Storage']=df3['Memory'].apply(lambda x: 508 if '508GB Hybrid' in x else 1000 if '1.0TB Hybrid' in x else 0)

df3['Hybrid_Storage'].unique()

#dropping memory as values are extracted
df3.drop(columns=['Memory'],inplace=True)

df3.head()

df3.info()

"""#GPU column"""

#There are lot of unique values in this GPU column we need to extract it
df3['Gpu'].unique()

#creating new column GPU Brand
df3['Gpu_Brand']=df3['Gpu'].apply(lambda x: x.split()[0])

df3['Gpu_Brand'].unique()

#drppimg GPU column as their is o more need
df3.drop(columns=['Gpu'],inplace=True)

df3.head()

"""#OPSys column"""

df3['OpSys'].unique()

#categorizing OpSys
df3['OpSys']=df3['OpSys'].apply(lambda x: 'Windows 11' if 'Windows 10 S' in x else 'macOS' if 'Mac OS X' in x else x)

df3['OpSys'].unique()

"""#Weight column"""

df3['Weight'].unique()

#checking error value
df3[df3['Weight']=='?']

#replacing error value and removing kg from weight column
df3['Weight']=df3['Weight'].str.replace('?','2.2kg')
df3['Weight']=df3['Weight'].str.replace('kg','')

#changing dataype of weight
df3['Weight']=df3['Weight'].astype('float')

df3.info()

#checking Outliers in weight
sns.boxplot(df3['Weight'])

#replacing outliers using IQR method
Q1=df3['Weight'].quantile(0.25)
Q3=df3['Weight'].quantile(0.75)

IQR=Q3-Q1

lower_limit=Q1-1.5*IQR
upper_limit=Q3+1.5*IQR

df3['Weight'].clip(lower_limit,upper_limit,inplace=True)

"""#Checking outliers after trimming outliers in weight column"""

sns.boxplot(df3['Weight'])

"""#Price column"""

df4=df3.copy()

sns.distplot(df4['Price'])

#performing log transformation
df4['Price']=np.log(df4["Price"])

#checking distribution after performing lagorthimic transformation
plt.figure(figsize=(10,4))
plt.subplot(1,2,2)
sns.histplot(df4['Price'], kde=True, color='green')
plt.title('Log-Transformed Price Distribution')
plt.tight_layout()
plt.show()

df4.columns

df4 = df4[['Company', 'TypeName', 'Ram', 'OpSys', 'Weight', 'Touchscreen',
       'IPS', 'ppi', 'CPU_Brand', 'SSD', 'HDD', 'Flash_Storage',
       'Hybrid_Storage', 'Gpu_Brand', 'Price']]

df4.head()

"""#Data visualizations
##Univariate,Bivariate and Multivariate Visualizations
"""

num_cols = ['Ram', 'Weight', 'ppi', 'SSD', 'HDD',
            'Flash_Storage', 'Hybrid_Storage', 'Price']

for col in num_cols:
    plt.figure(figsize=(12,5))

    plt.subplot(1,2,1)
    sns.histplot(df4[col], kde=True, bins=30, color='skyblue')
    plt.title(f"Distribution of {col}")

    plt.subplot(1,2,2)
    sns.boxplot(x=df4[col], color='lightgreen')
    plt.title(f"Boxplot of {col}")

    plt.tight_layout()
    plt.show()

for col in num_cols:
    if col != 'Price':
        plt.figure(figsize=(7,5))
        sns.scatterplot(x=df4[col], y=df4['Price'], alpha=0.6)
        plt.title(f"{col} vs Price")
        plt.show()

cat_cols = ['Company', 'TypeName', 'OpSys', 'CPU_Brand', 'Gpu_Brand']

for col in cat_cols:
    plt.figure(figsize=(10,5))
    sns.barplot(x=df4[col], y=df4['Price'], estimator='mean', errorbar=None,palette='coolwarm')
    plt.title(f"Average Price by {col}")
    plt.xticks(rotation=45)
    plt.show()

plt.figure(figsize=(10,7))
sns.heatmap(df4[num_cols].corr(), annot=True, cmap='YlGnBu')
plt.title("Correlation Heatmap for Numeric Features")
plt.show()

df5=df4.copy()

df5.info()

"""#2.Feature selection"""

#we are going to use only postively correleted column
df5.corr(numeric_only=True)['Price'].head(15)

df6=df5.copy()
df6.drop(columns=['Flash_Storage','Hybrid_Storage'],inplace=True)
df6.head()

"""#Modelling and Evaluation"""

#segregating the data into input and output
X=df6.drop(columns=['Price'])#X=independent variable
y=df6['Price']#Y=dependent variable

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder

!pip install xgboost

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb
from xgboost import XGBRegressor

#Splitting the data into tarin and test
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)
X_train.shape,X_test.shape,y_train.shape,y_test.shape

df6.columns

"""#Linear regression model"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse_output=False,drop='first'),[0,1,3,8,11])
],remainder='passthrough')

step2 = LinearRegression()

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""#KNN(K-nearest-neighbors) algorithm"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse_output=False,drop='first'),[0,1,3,8,11])
],remainder='passthrough')

step2 = KNeighborsRegressor(n_neighbors=3)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""#SVM Regressor"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse_output=False,drop='first'),[0,1,3,8,11])
],remainder='passthrough')

step2 = SVR(kernel='rbf',C=10000,epsilon=0.1)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""#Decision Tree Regressor"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse_output=False,drop='first'),[0,1,3,8,11])
],remainder='passthrough')

step2 = DecisionTreeRegressor(max_depth=8)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""#Random Fortest Regressor"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse_output=False,drop='first'),[0,1,3,8,11])
],remainder='passthrough')

step2 = RandomForestRegressor(n_estimators=100,
                              random_state=3,
                              max_samples=0.5,
                              max_features=0.75,
                              max_depth=15)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""#GradientBoost Regressor"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse_output=False,drop='first'),[0,1,3,8,11])
],remainder='passthrough')

step2 = GradientBoostingRegressor(n_estimators=500)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""#XGB Regressor"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse_output=False,drop='first'),[0,1,3,8,11])
],remainder='passthrough')

step2 = XGBRegressor(n_estimators=45,max_depth=5,learning_rate=0.5)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""#Hyperparameter Tuning for the best model"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor # Import RandomForestRegressor
from sklearn.model_selection import GridSearchCV


categorical_features = ['Company', 'TypeName', 'OpSys', 'CPU_Brand', 'Gpu_Brand']


numerical_features = ['Ram', 'Weight', 'Touchscreen', 'IPS', 'ppi', 'SSD', 'HDD']


# Create the ColumnTransformer
# It applies OneHotEncoder to categorical features and passes through numerical features
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'), categorical_features)
    ],
    remainder='passthrough' # Pass through the numerical columns
)

# Create the Pipeline: Preprocessing followed by the Estimator
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('estimator', RandomForestRegressor(random_state=42)) # The estimator to be tuned
])


# Define the parameter grid for the estimator (RandomForestRegressor)
# The parameters in the grid should be prefixed with the estimator's name in the pipeline ('estimator__')
param_grid = {
    'estimator__n_estimators': [100, 200, 300, 500],             # number of trees
    'estimator__max_depth': [None, 5, 10, 15, 20],               # depth of trees
    'estimator__min_samples_split': [2, 5, 10],                  # min samples to split an internal node
    'estimator__min_samples_leaf': [1, 2, 4, 5],                 # min samples per leaf
    'estimator__max_features': ['sqrt', 'log2'] # 'auto' is deprecated, use 'sqrt' or 'log2'
}

"""#Final Model"""

# Create the GridSearchCV object
grid_search = GridSearchCV(
    estimator=pipeline, # Use the pipeline as the estimator
    param_grid=param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1,
    verbose=2
)

# Fit the GridSearchCV object on the training data (X_train, y_train)
# The pipeline within GridSearchCV will handle the preprocessing
grid_search.fit(X_train, y_train)

# Get the best parameters
print("Best Parameters:", grid_search.best_params_)

# Get the best estimator (the fitted pipeline with the best parameters)
best_pipeline = grid_search.best_estimator_

#Train final model with the best parameters
best_model = grid_search.best_estimator_

#Make predictions6
y_pred = best_model.predict(X_test)

#Evaluate
print('R2 Score of random forest Regressor :', round(r2_score(y_test, y_pred),4))
print('MAE of random forest Regressor :', mean_absolute_error(y_test, y_pred))
print('MSE of random forest Regressor :', mean_squared_error(y_test, y_pred))
print('RMSE :', np.sqrt(mean_squared_error(y_test, y_pred)))

for col in df6.columns:

   print(df6[col].unique())

import joblib
# Save the trained model to a file
joblib.dump(best_model, 'laptop_price_model.pkl')
print(" Model saved successfully as 'laptop_price_model.pkl'")

"""#Real-time Predictions:"""

#Interactive laptop price predictor.
 # Handles case-insensitive user input.
 # Automatically calculates PPI from resolution + inches.
 # Matches categorical values exactly to training dataset categories.

import numpy as np
import pandas as pd

def predict_laptop_price(model):

    print("----- Enter Laptop Details for Price Prediction -----")

    # ----- VALID CATEGORIES (from dataset) -----
    valid_companies = ['Apple', 'HP', 'Acer', 'Asus', 'Dell', 'Lenovo', 'Chuwi', 'MSI',
                       'Microsoft', 'Toshiba', 'Huawei', 'Xiaomi', 'Vero', 'Razer',
                       'Mediacom', 'Samsung', 'Google', 'Fujitsu', 'LG']

    valid_typename = ['Ultrabook', 'Notebook', 'Gaming', '2 in 1 Convertible', 'Workstation', 'Netbook']

    valid_opsys = ['macOS', 'No OS', 'Windows 10', 'Linux', 'Windows 11', 'Chrome OS', 'Windows 7', 'Android']

    valid_cpu = ['Intel Core i5', 'Intel Core i7', 'AMD A9-Series', 'Intel Core i3',
                 'Other Intel Processor', 'AMD E-Series', 'Intel Atom', 'AMD A6-Series',
                 'Intel Celeron', 'AMD Ryzen', 'Intel Pentium', 'AMD FX', 'AMD A10-Series',
                 'AMD A8-Series', 'AMD A12-Series', 'AMD A4-Series', 'Samsung Cortex']

    valid_gpu = ['Intel', 'AMD', 'Nvidia', 'ARM']

    # Helper function: safely maps user input to valid categories
    def match_input(user_input, valid_list):
        user_input_lower = user_input.strip().lower()
        for item in valid_list:
            if item.lower() == user_input_lower:
                return item
        raise ValueError(f"Invalid input '{user_input}'. Choose from: {valid_list}")

    # ------------------ USER INPUTS ------------------
    company = match_input(input(f"Enter Company {valid_companies}: "), valid_companies)
    typename = match_input(input(f"Enter TypeName {valid_typename}: "), valid_typename)
    ram = int(input("Enter RAM (in GB): "))
    opsys = match_input(input(f"Enter Operating System {valid_opsys}: "), valid_opsys)
    weight = float(input("Enter Weight (in kg): "))
    touchscreen = int(input("Touchscreen? (1 = Yes, 0 = No): "))
    ips = int(input("IPS Display? (1 = Yes, 0 = No): "))
    screen_resolution = input("Enter Screen Resolution (e.g. 1920x1080): ").lower().strip()
    inches = float(input("Enter Screen Size (in Inches): "))
    cpu_brand = match_input(input(f"Enter CPU Brand {valid_cpu}: "), valid_cpu)
    ssd = int(input("Enter SSD Storage (in GB, e.g. 0, 256, 512, 1000): "))
    hdd = int(input("Enter HDD Storage (in GB, e.g. 0, 500, 1000, 2000): "))
    gpu_brand = match_input(input(f"Enter GPU Brand {valid_gpu}: "), valid_gpu)

    # ------------------ PPI CALCULATION ------------------
    try:
        X_res, Y_res = map(int, screen_resolution.split('*'))
    except:
        raise ValueError("Invalid screen resolution format! Use format like '1920*1080'.")

    ppi = ((X_res ** 2 + Y_res ** 2) ** 0.5) / inches

    # ------------------ DATAFRAME PREPARATION ------------------
    input_data = pd.DataFrame({
        'Company': [company],
        'TypeName': [typename],
        'Ram': [ram],
        'OpSys': [opsys],
        'Weight': [weight],
        'Touchscreen': [touchscreen],
        'IPS': [ips],
        'ppi': [ppi],
        'CPU_Brand': [cpu_brand],
        'SSD': [ssd],
        'HDD': [hdd],
        'Gpu_Brand': [gpu_brand]
    })

    # ------------------ PREDICTION ------------------
    log_price_pred = model.predict(input_data)[0]
    actual_price = np.exp(log_price_pred)

    print("\n Laptop Configuration:")
    print(input_data.to_string(index=False))
    print("\n Predicted Laptop Price: â‚¹", round(actual_price, 2))
    return round(actual_price, 2)

import joblib
# Load the saved model
best_model = joblib.load('laptop_price_model.pkl')
print("Model loaded successfully!")

predict_laptop_price(best_model)